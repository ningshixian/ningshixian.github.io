<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>My New Post</title>
    <link href="/2023/04/24/My-New-Post/"/>
    <url>/2023/04/24/My-New-Post/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/04/24/hello-world/"/>
    <url>/2023/04/24/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>LoRa 学习笔记</title>
    <link href="/2023/04/23/LoRa%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2023/04/23/LoRa%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="LoRa是什么？"><a href="#LoRa是什么？" class="headerlink" title="LoRa是什么？"></a>LoRa是什么？</h2><p>LoRA，出自论文<a href="https://arxiv.org/abs/2106.09685">《LoRA: Low-Rank Adaptation of Large Language Models》</a>，是Microsoft 于 2021 年推出的一项新技术，用于微调大型语言模型 (LLM)。<br>比如，GPT-3有1750亿参数，为了让它能干特定领域的活儿，需要做微调，但是如果直接对GPT-3做微调，成本太高太麻烦了。<br>LoRA的做法是，冻结预训练好的模型权重参数，然后在每个Transformer（Transforme就是GPT的那个T）块里注入可训练的层，由于不需要对模型的权重参数重新计算梯度，所以，大大减少了需要训练的计算量。<br>研究发现，LoRA的微调质量与全模型微调相当，我愿称之为神器。<br>要做个比喻的话，就好比是大模型的一个小模型，或者说是一个插件。<br>LoRA本来是给大语言模型准备的，但把它用在cross-attention layers（交叉关注层）也能影响用文字生成图片的效果。</p><h2 id="LoRa方法简介"><a href="#LoRa方法简介" class="headerlink" title="LoRa方法简介"></a>LoRa方法简介</h2><blockquote><p><a href="https://kexue.fm/archives/9590">梯度视角下的LoRA：简介、分析、猜测及推广</a></p></blockquote><p>LoRA借鉴了上述结果，提出对于预训练的参数矩阵$W_0∈ℝ^{m×n}$，我们不去直接微调$W_0$，而是对增量做低秩分解假设：</p><img src="/2023/04/23/LoRa%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.png" class="" title="image.png"><p>其中$U,V$之一用全零初始化，$W_0$固定不变，优化器只优化$U,V$。由于本征维度很小的结论，所以$r$我们可以取得很小，很多时候我们甚至可以直接取$1$。所以说，LoRA是一种参数高效的微调方法，至少被优化的参数量大大降低了。</p><img src="/2023/04/23/LoRa%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2.png" class="" title="image.png"><h2 id="PEFT对LORA的实现"><a href="#PEFT对LORA的实现" class="headerlink" title="PEFT对LORA的实现"></a>PEFT对LORA的实现</h2><p><a href="https://blog.csdn.net/weixin_44826203/article/details/129733930">https://blog.csdn.net/weixin_44826203/article/details/129733930</a></p><p><a href="https://mp.weixin.qq.com/s/bWl9Ke9dHmHPQEad-XZsyQ">https://mp.weixin.qq.com/s/bWl9Ke9dHmHPQEad-XZsyQ</a></p>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LoRa</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>🇨🇳中文NLP常用开源库整理</title>
    <link href="/2023/03/21/%F0%9F%87%A8%F0%9F%87%B3%E4%B8%AD%E6%96%87NLP%E5%B8%B8%E7%94%A8%E5%BC%80%E6%BA%90%E5%BA%93%E6%95%B4%E7%90%86/"/>
    <url>/2023/03/21/%F0%9F%87%A8%F0%9F%87%B3%E4%B8%AD%E6%96%87NLP%E5%B8%B8%E7%94%A8%E5%BC%80%E6%BA%90%E5%BA%93%E6%95%B4%E7%90%86/</url>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://github.com/crownpku/Awesome-Chinese-NLP">https://github.com/crownpku/Awesome-Chinese-NLP</a><br><a href="https://github.com/fighting41love">fighting41love</a>/<a href="https://github.com/fighting41love/funNLP">funNLP</a></p></blockquote><h2 id="Toolkits-综合NLP工具包"><a href="#Toolkits-综合NLP工具包" class="headerlink" title="Toolkits 综合NLP工具包"></a>Toolkits 综合NLP工具包</h2><p>中文：</p><ul><li><a href="http://thulac.thunlp.org/">THULAC 中文词法分析工具包</a> (⭐️1.8K) by 清华 (C++/Java/Python)</li><li><a href="https://github.com/baidu/lac">BaiduLac</a> (⭐️3.4K)  by 百度，支持分词，词性标注，命名实体识别，词重要性</li><li><a href="https://github.com/hankcs">hankcs</a>/<a href="https://github.com/hankcs/HanLP">HanLP</a> (⭐️28.5K)  面向生产环境的多语种自然语言处理工具包</li><li><a href="https://github.com/isnowfy/snownlp">SnowNLP</a> (⭐️6K) ，支持中文分词、词性标注、转换成拼音、TextRank算法、BM25等</li><li><a href="https://github.com/rsanshierli/EasyBert">EasyBert</a>，基于Pytorch的Bert应用，包括命名实体识别、情感分析、文本分类以及文本相似度等</li></ul><p>英文：</p><ul><li><a href="https://github.com/stanfordnlp/stanza">Stanza</a> by Stanford (Python) A Python NLP Library for Many Human Languages</li><li><a href="http://www.nltk.org/">NLTK</a> (Python) Natural Language Toolkit</li><li><a href="https://spacy.io/">spaCy</a> (Python) Industrial-Strength Natural Language Processing with a <a href="https://course.spacy.io/">online course</a></li><li><a href="https://github.com/jbesomi/texthero">texthero</a> Text preprocessing, representation and visualization from zero to hero.</li><li><a href="https://ningshixian.github.io/2018/11/05/allennlp%E5%AE%89%E8%A3%85/">AllenNLP</a> 一个基于 PyTorch 构建的 Apache 2.0 NLP 研究库，用于在各种语言任务上开发最先进的深度学习模型。</li></ul><h2 id="中文分词工具包"><a href="#中文分词工具包" class="headerlink" title="中文分词工具包"></a>中文分词工具包</h2><ul><li><a href="https://github.com/fxsjy/jieba">Jieba 结巴中文分词</a> (Python及大量其它编程语言衍生) 做最好的 Python 中文分词组件</li><li><a href="https://github.com/lancopku/pkuseg-python">北大中文分词工具</a> (Python) 高准确度中文分词工具，简单易用，跟现有开源工具相比大幅提高了分词的准确率。</li></ul><h2 id="信息提取工具包"><a href="#信息提取工具包" class="headerlink" title="信息提取工具包"></a>信息提取工具包</h2><ul><li><a href="https://github.com/crownpku/Information-Extraction-Chinese">Information-Extraction-Chinese</a> Chinese Named Entity Recognition with IDCNN/biLSTM+CRF, and Relation Extraction with biGRU+2ATT 中文实体识别与关系提取</li><li><a href="https://github.com/baidu/Familia">Familia</a> 百度出品的 A Toolkit for Industrial Topic Modeling，可用于语义表示和语义匹配</li></ul><p><strong>关键短语挖掘库：</strong></p><ul><li><a href="https://github.com/letiantian/TextRank4ZH">TextRank4ZH</a> 从中文文本中自动提取关键词和摘要</li><li><a href="https://github.com/blmoistawinde/HarvestText#%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8A%BD%E5%8F%96">HarvestText</a> 作者对比测试优于上者（仅限关键词抽取）</li><li><a href="https://github.com/dongrixinyu/chinese_keyphrase_extractor">JioNLP</a>: 在 tfidf 方法提取的碎片化的关键词（默认使用 pkuseg 的分词工具）基础上，将在文本中相邻的关键词合并，并根据权重进行调整，同时合并较为相似的短语，并结合 LDA 模型，寻找突出主题的词汇，增加权重，组合成结果进行返回。 <a href="https://github.com/baidu/lac"> </a></li><li><a href="https://github.com/baidu/lac">LAC</a> (paddlepaddle &gt;=2.0、LAC&gt;=2.1)  + DDParser </li></ul><p><strong>文本摘要：</strong></p><ul><li><a href="https://github.com/DataTurks-Engg/Entity-Recognition-In-Resumes-SpaCy">基于命名实体识别的简历自动摘要</a> </li><li><a href="https://github.com/Hellisotherpeople/CX_DB8">基于BERT等最新语言模型的抽取式摘要提取</a>        </li><li><a href="https://mp.weixin.qq.com/s/gDZyTbM1nw3fbEnU--y3nQ">Python利用深度学习进行文本摘要的综合指南</a>        </li><li><a href="https://github.com/theamrzaki/text_summurization_abstractive_methods">(Colab)抽象文本摘要实现集锦</a></li></ul><h2 id="QA-amp-Chatbot-工具包"><a href="#QA-amp-Chatbot-工具包" class="headerlink" title="QA &amp; Chatbot 工具包"></a>QA &amp; Chatbot 工具包</h2><ul><li><a href="https://github.com/RasaHQ/rasa_nlu">Rasa NLU</a> (Python) turn natural language into structured data, a Chinese fork at <a href="https://github.com/crownpku/Rasa_NLU_Chi">Rasa NLU Chi</a></li><li><a href="https://github.com/RasaHQ/rasa_core">Rasa Core</a> (Python) machine learning based dialogue engine for conversational software</li><li><a href="https://github.com/deepmipt/DeepPavlov">DeepPavlov</a> (Python) An open source library for building end-to-end dialog systems and training chatbots.</li><li><a href="https://github.com/gunthercox/ChatterBot">Chatterbot</a> (Python) ChatterBot is a machine learning, conversational dialog engine for creating chat bots.</li><li><a href="https://github.com/Doragd/Chinese-Chatbot-PyTorch-Implementation">Chinese-Chatbot-PyTorch-Implementation</a> 根据自己的语料训练出自己想要的聊天机器人，可以用于智能客服、在线问答、智能聊天等场景</li><li><a href="https://github.com/GaoQ1/rasa_chatbot_cn">rasa_chatbot_cn</a> 基于最新版本rasa搭建的对话系统</li></ul><h2 id="文本匹配开源库"><a href="#文本匹配开源库" class="headerlink" title="文本匹配开源库"></a>文本匹配开源库</h2><div class="table-container"><table><thead><tr><th>资源名（Name）</th><th>描述（Description）</th><th>链接</th></tr></thead><tbody><tr><td>句子、QA相似度匹配MatchZoo</td><td>文本相似度匹配算法的集合，包含多个深度学习的方法，值得尝试。</td><td><a href="https://github.com/NTMC-Community/MatchZoo">github</a></td></tr><tr><td>中文问题句子相似度计算比赛及方案汇总</td><td></td><td><a href="https://github.com/ShuaichiLi/Chinese-sentence-similarity-task">github</a></td></tr><tr><td>similarity相似度计算工具包</td><td>java编写,用于词语、短语、句子、词法分析、情感分析、语义分析等相关的相似度计算</td><td><a href="https://github.com/shibing624/similarity">github</a></td></tr><tr><td>中文词语相似度计算方法</td><td>综合了同义词词林扩展版与知网（Hownet）的词语相似度计算方法，词汇覆盖更多、结果更准确。</td><td><a href="https://github.com/yaleimeng/Final_word_Similarity">gihtub</a></td></tr><tr><td>Python字符串相似性算法库</td><td></td><td><a href="https://github.com/luozhouyang/python-string-similarity">github</a></td></tr></tbody></table></div><h2 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h2><ul><li><p>NeuralNLP-NeuralClassifier腾讯开源深度学习文本分类工具 <a href="https://github.com/Tencent/NeuralNLP-NeuralClassifier">github</a></p><h2 id="文本聚类"><a href="#文本聚类" class="headerlink" title="文本聚类"></a>文本聚类</h2></li><li><p>TextCluster短文本聚类预处理模块 Short text cluster <a href="https://github.com/RandyPen/TextCluster">github</a></p></li></ul><h2 id="文本数据增强"><a href="#文本数据增强" class="headerlink" title="文本数据增强"></a>文本数据增强</h2><div class="table-container"><table><thead><tr><th>资源名（Name）</th><th>描述（Description）</th><th>链接</th></tr></thead><tbody><tr><td>中文NLP数据增强（EDA）工具</td><td></td><td><a href="https://github.com/zhanlaoban/eda_nlp_for_Chinese">github</a></td></tr><tr><td>英文NLP数据增强工具</td><td></td><td><a href="https://github.com/makcedward/nlpaug">github</a></td></tr><tr><td>一键中文数据增强工具</td><td></td><td><a href="https://github.com/425776024/nlpcda">github</a></td></tr><tr><td>数据增强在机器翻译及其他nlp任务中的应用及效果</td><td></td><td><a href="https://mp.weixin.qq.com/s/_aVwSWuYho_7MUT0LuFgVA">link</a></td></tr><tr><td>NLP数据增广资源集</td><td></td><td><a href="https://github.com/quincyliang/nlp-data-augmentation">github</a></td></tr></tbody></table></div><h2 id="Learning-Materials-学习资料"><a href="#Learning-Materials-学习资料" class="headerlink" title="Learning Materials 学习资料"></a>Learning Materials 学习资料</h2><ul><li><a href="https://github.com/exacity/deeplearningbook-chinese">中文Deep Learning Book</a></li><li><a href="http://web.stanford.edu/class/cs224n/syllabus.html">Stanford CS224n Natural Language Processing with Deep Learning 2017</a></li><li><a href="https://github.com/oxford-cs-deepnlp-2017">Oxford CS DeepNLP 2017</a></li><li>[Course materials for Georgia Tech CS 4650 and 7650, “Natural Language”] (<a href="https://github.com/jacobeisenstein/gt-nlp-class">https://github.com/jacobeisenstein/gt-nlp-class</a>)</li><li><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a> by Dan Jurafsky and James H. Martin</li><li><a href="http://www.52nlp.cn/">52nlp 我爱自然语言处理</a></li><li><a href="http://www.hankcs.com/">hankcs 码农场</a></li><li><a href="https://github.com/Roshanson/TextInfoExp">文本处理实践课资料</a> 文本处理实践课资料，包含文本特征提取（TF-IDF），文本分类，文本聚类，word2vec训练词向量及同义词词林中文词语相似度计算、文档自动摘要，信息抽取，情感分析与观点挖掘等实验。</li><li><a href="https://github.com/Kyubyong/nlp_tasks">nlp_tasks</a> Natural Language Processing Tasks and Selected References</li><li><a href="https://github.com/zibuyu/research_tao">NLP研究入门之道</a> from清华刘知远老师</li><li><a href="https://chinesenlp.xyz/#/">Chinese NLP</a> Shared tasks, datasets and state-of-the-art results for Chinese Natural Language Processing</li></ul><h2 id="医疗自然语言处理"><a href="#医疗自然语言处理" class="headerlink" title="医疗自然语言处理"></a>医疗自然语言处理</h2><div class="table-container"><table><thead><tr><th>资源名（Name）</th><th>描述（Description）</th><th>链接</th></tr></thead><tbody><tr><td>中文医学NLP公开资源整理</td><td></td><td><a href="https://github.com/GanjinZero/awesome_Chinese_medical_NLP">github</a></td></tr><tr><td>spaCy 医学文本挖掘与信息提取</td><td></td><td><a href="https://github.com/NLPatVCU/medaCy">github</a></td></tr><tr><td>构建医疗实体识别的模型</td><td>包含词典和语料标注，基于python</td><td><a href="https://github.com/yixiu00001/LSTM-CRF-medical">github</a></td></tr><tr><td>基于医疗领域知识图谱的问答系统</td><td></td><td><a href="https://github.com/zhihao-chen/QASystemOnMedicalGraph">github</a></td></tr><tr><td>Chinese medical dialogue data 中文医疗对话数据集</td><td></td><td><a href="https://github.com/Toyhom/Chinese-medical-dialogue-data">github</a></td></tr><tr><td>一个大规模医疗对话数据集</td><td>包含110万医学咨询，400万条医患对话</td><td><a href="https://github.com/UCSD-AI4H/Medical-Dialogue-System">github</a></td></tr><tr><td>新冠肺炎相关数据</td><td>新冠及其他类型肺炎中文医疗对话数据集；清华大学等机构的开放数据源（COVID-19）</td><td><a href="https://www.aminer.cn/data-covid19/">github</a></td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>中文NLP库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>🇨🇳中文预训练模型研究进展&amp;整理</title>
    <link href="/2023/03/21/%F0%9F%87%A8%F0%9F%87%B3%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95&amp;%E6%95%B4%E7%90%86/"/>
    <url>/2023/03/21/%F0%9F%87%A8%F0%9F%87%B3%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95&amp;%E6%95%B4%E7%90%86/</url>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://www.jsjkx.com/CN/article/openArticlePDF.jsp?id=20915">https://www.jsjkx.com/CN/article/openArticlePDF.jsp?id=20915</a></p></blockquote><p>近两年,中文预训练模型受 到广大学者的关注并取得了一定的研究成果.为了阐明现有 的中文预训练模型,本节主要从以下６个方面对现有的预训练 模型进行分类,图３展示了典型的中文预训练模型的分类图. </p><ol><li>预训练模型的方法改进,主要包括掩码方式的转变、 位置编码的转变、LN 层的位置变化、MoE 层的使用、多粒度训练和其他改进. </li><li>融入外部信息的预训练,主要包括命名实体、知识图 谱、语言学知识和特定知识.</li><li>关于多模态融合的预训练模型. </li><li>侧重于高效计算的预训练,主要包括数据处理阶段、 预训练阶段以及技术优化. </li><li>指特定领域的预训练,主要包括对话系统和其他领域 的预训练模型. </li><li>介绍一些其他变体,主要侧重于典型的英文预训练模 型开源的中文版本.</li></ol><img src="/2023/03/21/%F0%9F%87%A8%F0%9F%87%B3%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95&%E6%95%B4%E7%90%86/1680254358588.png" class="" title="image.png"><h2 id="开源的中文预训练模型汇总"><a href="#开源的中文预训练模型汇总" class="headerlink" title="开源的中文预训练模型汇总"></a>开源的中文预训练模型汇总</h2><blockquote><p><a href="https://github.com/lonePatient">lonePatient</a>/<a href="https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models">awesome-pretrained-chinese-nlp-models</a></p></blockquote><h3 id="NLU系列"><a href="#NLU系列" class="headerlink" title="NLU系列"></a>NLU系列</h3><div class="table-container"><table><thead><tr><th>模型</th><th>版本</th><th>作者</th><th>源地址</th><th>应用领域</th></tr></thead><tbody><tr><td>ChineseBERT</td><td>base</td><td><a href="https://github.com/ShannonAI">ShannonAI</a></td><td><a href="https://github.com/ShannonAI/ChineseBert">github</a></td><td>通用</td></tr><tr><td>NEZHA-base</td><td>base</td><td><a href="https://github.com/huawei-noah">HUAWEI</a></td><td><a href="https://github.com/huawei-noah/Pretrained-Language-Model">github</a></td><td>通用</td></tr><tr><td>MacBERT-base</td><td>base</td><td><a href="https://github.com/ymcui">Yiming Cui</a></td><td><a href="https://github.com/ymcui/MacBERT">github</a></td><td>通用</td></tr><tr><td>WoBERT</td><td>base</td><td><a href="https://github.com/ZhuiyiTechnology">ZhuiyiTechnology</a></td><td><a href="https://github.com/ZhuiyiTechnology/WoBERT">github</a></td><td>通用</td></tr><tr><td>WoBERT-plus</td><td>base</td><td><a href="https://github.com/ZhuiyiTechnology">ZhuiyiTechnology</a></td><td><a href="https://github.com/ZhuiyiTechnology/WoBERT">github</a></td><td>通用</td></tr><tr><td>ZEN-Base</td><td>base</td><td><a href="https://github.com/sinovation">Sinovation Ventures AI Institute</a></td><td><a href="https://github.com/sinovation/ZEN">github</a></td><td>通用</td></tr><tr><td>ernie-3.0-base</td><td>base</td><td><a href="https://github.com/PaddlePaddle">PaddlePaddle</a></td><td><a href="https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/ernie-3.0">github</a></td><td>通用</td></tr><tr><td>roformer</td><td>base(L12)</td><td><a href="https://github.com/ZhuiyiTechnology">ZhuiyiTechnology</a></td><td><a href="https://github.com/ZhuiyiTechnology/roformer">github</a></td><td>通用</td></tr><tr><td>roformerV2</td><td>base(L12)</td><td><a href="https://github.com/ZhuiyiTechnology">ZhuiyiTechnology</a></td><td><a href="https://github.com/ZhuiyiTechnology/roformer-v2">github</a></td><td>通用</td></tr><tr><td>LatticeBERT</td><td>base(L12)</td><td><a href="https://github.com/alibaba">Alibaba</a></td><td><a href="https://github.com/alibaba/AliceMind/tree/main/LatticeBERT">github</a></td><td>通用</td></tr><tr><td>Mengzi-BERT</td><td>base(L12)</td><td><a href="https://github.com/Langboat">Langboat</a></td><td><a href="https://github.com/Langboat/Mengzi">github</a></td><td>通用</td></tr><tr><td>bloom-6b4-zh</td><td>6B(L30)</td><td><a href="https://huggingface.co/Langboat">Langboat</a></td><td><a href="https://github.com/huggingface/transformers">github</a></td><td>通用</td></tr><tr><td>TaCL</td><td>base(L12)</td><td><a href="https://github.com/yxuansu">yxuansu</a></td><td><a href="https://github.com/yxuansu/TaCL">github</a></td><td>通用</td></tr><tr><td>chinese_GAU-alpha-char_L-24_H-768</td><td>base</td><td><a href="https://github.com/ZhuiyiTechnology">ZhuiyiTechnology</a></td><td><a href="https://github.com/ZhuiyiTechnology/GAU-alpha">github</a></td><td>通用</td></tr><tr><td>pai-ckbert-base-zh</td><td>base</td><td><a href="https://github.com/alibaba">Alibaba</a></td><td><a href="https://huggingface.co/alibaba-pai">github</a></td><td>通用</td></tr><tr><td>Chinese-LERT-base</td><td>400m</td><td><a href="https://github.com/ymcui">Yiming Cui</a></td><td><a href="https://github.com/ymcui/LERT">github</a></td><td>通用</td></tr><tr><td></td><td></td><td></td><td></td></tr></tbody></table></div><h3 id="NLG系列"><a href="#NLG系列" class="headerlink" title="NLG系列"></a>NLG系列</h3><div class="table-container"><table><thead><tr><th>模型</th><th>版本</th><th>类型</th><th>源地址</th><th>应用领域</th></tr></thead><tbody><tr><td>CDial-GPTLCCC-base</td><td>base</td><td>GPT</td><td><a href="https://github.com/thu-coai/CDial-GPT">CDial-GPT</a></td><td>中文对话</td></tr><tr><td>roformer-gpt</td><td>base(L12)</td><td>GPT</td><td><a href="https://github.com/ZhuiyiTechnology/roformer">github</a></td><td>通用</td></tr><tr><td>NEZHA-Gen</td><td>base</td><td>GPT</td><td><a href="https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/NEZHA-Gen-TensorFlow">github</a></td><td>通用</td></tr><tr><td>CPM</td><td>26亿参数</td><td><a href="https://cpm.baai.ac.cn/">项目首页</a></td><td><a href="https://github.com/TsinghuaAI/CPM-Generate">github</a></td><td>通用</td></tr><tr><td>Mengzi-T5</td><td>base(L12)</td><td>T5</td><td><a href="https://github.com/Langboat/Mengzi">github</a></td><td>通用</td></tr><tr><td>盘古α-2.6B</td><td>2.6G</td><td><a href="https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha/src/branch/master">项目首页</a></td><td><a href="https://git.openi.org.cn/PCL-Platform.Intelligence/PanGu-Alpha">github</a></td><td>通用</td></tr><tr><td>EVA2.0-base</td><td>base</td><td><a href="https://wudaoai.cn/model/detail/EVA">项目首页</a></td><td><a href="https://github.com/thu-coai/EVA">github</a></td><td>中文开放域对话</td></tr><tr><td>BART-base</td><td>base</td><td>Seq2Seq</td><td><a href="https://github.com/fastnlp/CPT">github</a></td><td>中文通用</td></tr><tr><td>Wenzhong</td><td>large(L24)</td><td>GPT2</td><td><a href="https://github.com/IDEA-CCNL">IDEA-CCNL</a></td><td><a href="https://github.com/IDEA-CCNL/Fengshenbang-LM">github</a></td></tr><tr><td>Yuyuan</td><td>large(L24)</td><td>GPT2</td><td><a href="https://github.com/IDEA-CCNL">IDEA-CCNL</a></td><td><a href="https://github.com/IDEA-CCNL/Fengshenbang-LM">github</a></td></tr><tr><td>ChatYuan</td><td>large</td><td>T5</td><td><a href="https://github.com/clue-ai">ClueAI</a></td><td><a href="https://github.com/clue-ai/ChatYuan">github</a></td></tr></tbody></table></div><h3 id="NLU-NLG系列"><a href="#NLU-NLG系列" class="headerlink" title="NLU-NLG系列"></a>NLU-NLG系列</h3><div class="table-container"><table><thead><tr><th>模型</th><th>版本</th><th>作者</th><th>源地址</th><th>应用领域</th></tr></thead><tbody><tr><td>SimBERT Base</td><td>base</td><td><a href="https://github.com/ZhuiyiTechnology">ZhuiyiTechnology</a></td><td><a href="https://github.com/ZhuiyiTechnology/pretrained-models">github</a></td><td>通用</td></tr><tr><td>roformer-sim</td><td>base(L12)</td><td><a href="https://github.com/ZhuiyiTechnology">ZhuiyiTechnology</a></td><td><a href="https://github.com/ZhuiyiTechnology/roformer-sim">github</a></td><td>通用</td></tr><tr><td>roformer-sim-v2</td><td>base(L12)</td><td><a href="https://github.com/ZhuiyiTechnology">ZhuiyiTechnology</a></td><td><a href="https://github.com/ZhuiyiTechnology/roformer-sim">github</a></td><td>通用</td></tr><tr><td>Zhouwenwang</td><td>roformer</td><td>-</td><td>-</td><td>-</td></tr><tr><td>base(L12)</td><td><a href="https://huggingface.co/IDEA-CCNL/Zhouwenwang-110M">huggingface</a></td><td><a href="https://github.com/IDEA-CCNL/Fengshenbang-LM">github</a></td><td>中文通用</td><td>-</td></tr><tr><td>CPM-2</td><td>110亿参数</td><td><a href="https://github.com/BAAI-WuDao">BAAI-WuDao</a></td><td><a href="https://github.com/BAAI-WuDao/Model">github</a></td><td>通用</td></tr><tr><td>CPT-base</td><td>base(L12)</td><td><a href="https://github.com/fastnlp">fastNLP</a></td><td><a href="https://github.com/fastnlp/CPT">github</a></td><td>通用</td></tr><tr><td>OPD</td><td>6.3B</td><td><a href="https://github.com/thu-coai">thu-coai</a></td><td><a href="https://github.com/thu-coai/OPD">github</a></td><td>中文开放域对话</td></tr></tbody></table></div><h3 id="LLM"><a href="#LLM" class="headerlink" title="LLM"></a>LLM</h3><p>大规模语言模型：表格中只罗列出参数量大于10B以上模型。</p><div class="table-container"><table><thead><tr><th>模型</th><th>大小</th><th>结构</th><th>语言</th><th>下载</th><th>机构</th><th>项目地址</th><th>时间</th><th>文献</th></tr></thead><tbody><tr><td>flan-ul2</td><td>20B</td><td>encoder-decoder</td><td>多语言</td><td><a href="https://huggingface.co/google/flan-ul2/tree/main">ckpt</a></td><td><a href="https://ai.google/research/">Google</a></td><td><a href="https://github.com/google-research/google-research/tree/master/ul2">ul2</a></td><td>2023-03</td><td><a href="https://arxiv.org/pdf/2205.05131v3.pdf">paper</a></td></tr><tr><td>CPM-Bee</td><td>10B</td><td>Decoder</td><td>中英文</td><td>待发布</td><td><a href="https://live.openbmb.org/">OpenBMB</a></td><td><a href="https://github.com/OpenBMB/CPM-Live">CPM-Live</a></td><td>2023-01</td><td>-</td></tr><tr><td>BLOOM</td><td>176B</td><td>Decoder</td><td>多语言</td><td><a href="https://huggingface.co/bigscience/bloom">ckpt-95000</a></td><td><a href="https://github.com/bigscience-workshop">BigScience</a></td><td><a href="https://github.com/bigscience-workshop/Megatron-DeepSpeed">Megatron-DeepSpeed</a></td><td>2022-11</td><td><a href="https://arxiv.org/pdf/2211.05100.pdf">paper</a></td></tr><tr><td><em>BLOOMZ</em></td><td>176B</td><td>Decoder</td><td>多语言</td><td><a href="https://huggingface.co/bigscience/bloomz">ckpt-498</a></td><td><a href="https://github.com/bigscience-workshop">BigScience</a></td><td><a href="https://github.com/bigscience-workshop/Megatron-DeepSpeed">Megatron-DeepSpeed</a></td><td>2022-11</td><td><a href="https://arxiv.org/abs/2211.01">paper</a></td></tr><tr><td>flan-t5-xxl</td><td>11B</td><td>encoder-decoder</td><td>多语言</td><td><a href="https://huggingface.co/google/flan-t5-xxl">ckpt</a></td><td><a href="https://ai.google/research/">Google</a></td><td><a href="https://github.com/google-research/t5x">t5x</a></td><td>2022-11</td><td><a href="https://arxiv.org/pdf/2210.11416.pdf">paper</a></td></tr><tr><td>CPM-Ant+</td><td>10B</td><td>Decoder</td><td>中英文</td><td><a href="http://openbmb.oss-cn-hongkong.aliyuncs.com/model_center/cpm-ant-plus-10b/cpm-ant-plus-10b.zip">ckpt</a></td><td><a href="https://live.openbmb.org/">OpenBMB</a></td><td><a href="https://github.com/OpenBMB/CPM-Live">CPM-Live</a></td><td>2022-10</td><td><a href="https://www.openbmb.org/community/blogs/blogpage?id=98afef2ce45f4fe9a4bc15a66d7ccb92">blog</a></td></tr><tr><td>GLM</td><td>130B</td><td>Decoder</td><td>中英文</td><td><a href="https://docs.google.com/forms/d/e/1FAIpQLSehr5Dh_i3TwACmFFi8QEgIVNYGmSPwV0GueIcsUev0NEfUug/viewform">申请下载</a></td><td><a href="https://github.com/THUDM">清华大学</a></td><td><a href="https://github.com/THUDM/GLM-130B">GLM-130B</a></td><td>2022-10</td><td><a href="http://arxiv.org/abs/2210.02414">paper</a></td></tr><tr><td>CPM-Ant</td><td>10B</td><td>Decoder</td><td>中文</td><td><a href="https://openbmb.oss-cn-hongkong.aliyuncs.com/model_center/cpmlive-10b/cpm_live_10B.zip">ckpt</a></td><td><a href="https://live.openbmb.org/">OpenBMB</a></td><td><a href="https://github.com/OpenBMB/CPM-Live">CPM-Live</a></td><td>2022-09</td><td><a href="https://www.openbmb.org/community/blogs/blogpage?id=98afef2ce45f4fe9a4bc15a66d7ccb92">blog</a></td></tr><tr><td>GLM</td><td>10B</td><td>Decoder</td><td>中文</td><td><a href="https://lfs.aminer.cn/misc/cogview/glm-10b-chinese.zip">ckpt</a></td><td><a href="https://github.com/THUDM">清华大学</a></td><td><a href="https://github.com/THUDM/GLM">GLM</a></td><td>2022-09</td><td><a href="https://arxiv.org/abs/2103.10360">paper</a></td></tr><tr><td>源1.0</td><td>245B</td><td>Decoder</td><td>中文</td><td><a href="https://air.inspur.com/home">API申请</a></td><td><a href="https://air.inspur.com/home">浪潮</a></td><td><a href="https://github.com/Shawn-Inspur/Yuan-1.0">Yian-1.0</a></td><td>2021-09</td><td><a href="https://arxiv.org/abs/2110.04725">paper</a></td></tr><tr><td>CPM-2</td><td>11B</td><td>encoder-decoder</td><td>中文</td><td><a href="https://resource.wudao.baai.ac.cn/home?ind=2&amp;name=WuDao WenYuan&amp;id=1394901846484627456">申请下载</a></td><td><a href="https://www.baai.ac.cn/">智源研究院</a></td><td><a href="https://github.com/TsinghuaAI/CPM">CPM</a></td><td>2021-06</td><td><a href="https://arxiv.org/abs/2106.10715">paper</a></td></tr><tr><td>CPM-2</td><td>10B</td><td>encoder-decoder</td><td>中英文</td><td><a href="https://resource.wudao.baai.ac.cn/home?ind=2&amp;name=WuDao WenYuan&amp;id=1394901846484627456">申请下载</a></td><td><a href="https://www.baai.ac.cn/">智源研究院</a></td><td><a href="https://github.com/TsinghuaAI/CPM">CPM</a></td><td>2021-06</td><td><a href="https://arxiv.org/abs/2106.10715">paper</a></td></tr><tr><td>PanGu-Alpha</td><td>13B</td><td>Decoder</td><td>中文</td><td><a href="https://openi.pcl.ac.cn/PCL-Platform.Intelligence/PanGu-Alpha">ckpt</a></td><td><a href="https://openi.pcl.ac.cn/PCL-Platform.Intelligence">鹏城实验室</a></td><td><a href="https://openi.pcl.ac.cn/PCL-Platform.Intelligence/PanGu-Alpha">PanGu-Alpha</a></td><td>2021-05</td><td><a href="https://arxiv.org/pdf/2104.12369.pdf">paper</a></td></tr><tr><td>PanGu-Alpha</td><td>200B</td><td>Decoder</td><td>中文</td><td>待发布</td><td><a href="https://openi.pcl.ac.cn/PCL-Platform.Intelligence">鹏城实验室</a></td><td><a href="https://openi.pcl.ac.cn/PCL-Platform.Intelligence/PanGu-Alpha">PanGu-Alpha</a></td><td>2021-05</td><td><a href="https://arxiv.org/pdf/2104.12369.pdf">paper</a></td></tr><tr><td>PLUG</td><td>27B</td><td>encoder-decoder</td><td>中文</td><td><a href="https://www.alice-mind.com/portal#/">申请下载</a></td><td><a href="https://www.alice-mind.com/portal#/">阿里巴巴</a></td><td><a href="https://github.com/alibaba/AliceMind">AliceMind</a></td><td>2021-04</td><td>-</td></tr><tr><td>GPT-3</td><td>13B</td><td>Decoder</td><td>中文</td><td>待发布</td><td><a href="https://modelscope.cn/organization/damo">达摩院</a></td><td><a href="https://modelscope.cn/models/damo/nlp_gpt3_text-generation_13B/summary">GPT-3预训练生成模型</a></td><td>2021-04</td><td>-</td></tr><tr><td>GPT-3</td><td>30B</td><td>Decoder</td><td>中文</td><td>待发布</td><td><a href="https://modelscope.cn/organization/damo">达摩院</a></td><td><a href="https://modelscope.cn/models/damo/nlp_gpt3_text-generation_30B/summary">GPT-3预训练生成模型</a></td><td>2021-04</td><td>-</td></tr></tbody></table></div><h3 id="ChatLLM"><a href="#ChatLLM" class="headerlink" title="ChatLLM"></a>ChatLLM</h3><p>具备问答和对话等功能的大型语言模型。</p><div class="table-container"><table><thead><tr><th>模型</th><th>大小</th><th>结构</th><th>语言</th><th>下载</th><th>机构/个人</th><th>项目地址</th><th>时间</th></tr></thead><tbody><tr><td>ChatLLaMA</td><td>7B</td><td>Decoder</td><td>多语言</td><td><a href="https://huggingface.co/P01son/ChatLLaMA-zh-7B">ckpt</a></td><td><a href="https://github.com/ydli-ai">Li Yudong</a></td><td><a href="https://github.com/ydli-ai/Chinese-ChatLLaMA">Chinese-ChatLLaMA</a></td><td>2023-03</td></tr><tr><td>Chinese-Vicuna</td><td>13B</td><td>Decoder</td><td>中文</td><td><a href="https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-13b-belle-and-guanaco">ckpt</a></td><td><a href="https://github.com/Facico">Facico</a></td><td><a href="https://github.com/Facico/Chinese-Vicuna">Chinese-Vicuna</a></td><td>2023-03</td></tr><tr><td>Chinese-Vicuna</td><td>7B</td><td>Decoder</td><td>中文</td><td><a href="https://huggingface.co/Chinese-Vicuna/Chinese-Vicuna-lora-7b-belle-and-guanaco">ckpt</a></td><td><a href="https://github.com/Facico">Facico</a></td><td><a href="https://github.com/Facico/Chinese-Vicuna">Chinese-Vicuna</a></td><td>2023-03</td></tr><tr><td>ChatYuan-V2</td><td>0.7B</td><td>Encoder-Decder</td><td>中英文</td><td><a href="https://huggingface.co/ClueAI/ChatYuan-large-v2/tree/main">ckpt</a></td><td><a href="https://github.com/clue-ai">元语智能</a></td><td><a href="https://github.com/clue-ai/ChatYuan">ChatYuan</a></td><td>2023-03</td></tr><tr><td>Chinese-LLaMA-Alpaca</td><td>7B</td><td>Decoder</td><td>中文</td><td><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca">lora-ckpt</a></td><td><a href="https://github.com/ymcui">Yiming Cui</a></td><td><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca">Chinese-LLaMA-Alpaca</a></td><td>2023-03</td></tr><tr><td>Luotuo</td><td>7B</td><td>Decoder</td><td>中文</td><td><a href="https://huggingface.co/silk-road/luotuo-lora-7b-0.3">ckpt</a></td><td>商汤科技&amp;华中师范大学</td><td><a href="https://github.com/LC1332/Chinese-alpaca-lora">Chinese-alpaca-lora</a></td><td>2023-03</td></tr><tr><td>BELLE-LLAMA</td><td>7B</td><td>Decoder</td><td>中英文</td><td><a href="https://huggingface.co/BelleGroup/BELLE-LLAMA-7B-2M">ckpt</a></td><td><a href="https://github.com/LianjiaTech">贝壳</a></td><td><a href="https://github.com/LianjiaTech/BELLE">BELLE</a></td><td>2023-03</td></tr><tr><td>BELLE-BLOOM</td><td>7B</td><td>Decoder</td><td>中英文</td><td><a href="https://huggingface.co/BelleGroup/BELLE-7B-2M">ckpt</a></td><td><a href="https://github.com/LianjiaTech">贝壳</a></td><td><a href="https://github.com/LianjiaTech/BELLE">BELLE</a></td><td>2023-03</td></tr><tr><td>ChatGLM-6B</td><td>6B</td><td>Decoder</td><td>中英双语</td><td><a href="https://huggingface.co/THUDM/chatglm-6b">ckpt</a></td><td><a href="https://github.com/THUDM">清华大学</a></td><td><a href="https://github.com/THUDM/ChatGLM-6B">ChatGLM-6B</a></td><td>2023-03</td></tr><tr><td>ChatRWKV</td><td>7B</td><td>RNN</td><td>中/英文</td><td><a href="https://huggingface.co/BlinkDL/rwkv-4-pile-7b/tree/main">ckpt</a></td><td><a href="https://github.com/BlinkDL">BlinkDL</a></td><td><a href="https://github.com/BlinkDL/ChatRWKV">ChatRWKV</a></td><td>2023-01</td></tr></tbody></table></div><hr><h2 id="预训练模型的方法改进"><a href="#预训练模型的方法改进" class="headerlink" title="预训练模型的方法改进"></a>预训练模型的方法改进</h2><h3 id="掩码方式的转变"><a href="#掩码方式的转变" class="headerlink" title="掩码方式的转变"></a>掩码方式的转变</h3><img src="/2023/03/21/%F0%9F%87%A8%F0%9F%87%B3%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95&%E6%95%B4%E7%90%86/1680254440948-bf274532-c2dd-4625-975b-41d06470d167.png" class="" title="image.png"><h3 id="位置编码的转变"><a href="#位置编码的转变" class="headerlink" title="位置编码的转变"></a>位置编码的转变</h3><h3 id="LN-的位置变化"><a href="#LN-的位置变化" class="headerlink" title="LN 的位置变化"></a>LN 的位置变化</h3><img src="/2023/03/21/%F0%9F%87%A8%F0%9F%87%B3%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95&%E6%95%B4%E7%90%86/1680254515526-1479b790-7c7e-412f-9d4a-d4b404d97f1b.png" class="" title="image.png"><h3 id="MoE层的使用"><a href="#MoE层的使用" class="headerlink" title="MoE层的使用"></a>MoE层的使用</h3><img src="/2023/03/21/%F0%9F%87%A8%F0%9F%87%B3%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E7%A0%94%E7%A9%B6%E8%BF%9B%E5%B1%95&%E6%95%B4%E7%90%86/1680254540425-dd3af49f-371b-457b-a79e-8fcf8842e47f.png" class="" title="image.png">]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>中文预训练模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>🇨🇳中文常用语料Corpus整理</title>
    <link href="/2023/03/21/%F0%9F%87%A8%F0%9F%87%B3%E4%B8%AD%E6%96%87%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%96%99Corpus%E6%95%B4%E7%90%86/"/>
    <url>/2023/03/21/%F0%9F%87%A8%F0%9F%87%B3%E4%B8%AD%E6%96%87%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%96%99Corpus%E6%95%B4%E7%90%86/</url>
    
    <content type="html"><![CDATA[<blockquote><p><a href="https://github.com/InsaneLife">InsaneLife</a>/<a href="https://github.com/InsaneLife/ChineseNLPCorpus">ChineseNLPCorpus</a><br><a href="https://github.com/SophonPlus">SophonPlus</a>/<a href="https://github.com/SophonPlus/ChineseNlpCorpus">ChineseNlpCorpus</a><br><a href="https://github.com/brightmart">brightmart</a>/<a href="https://github.com/brightmart/nlp_chinese_corpus">nlp_chinese_corpus</a><br><a href="https://github.com/ningshixian">ningshixian</a>/<a href="https://github.com/ningshixian/NLP-zoo">NLP-zoo</a>、<a href="https://github.com/fighting41love">fighting41love</a>/<a href="https://github.com/fighting41love/funNLP">funNLP</a></p></blockquote><h2 id="中文词典"><a href="#中文词典" class="headerlink" title="中文词典"></a>中文词典</h2><ul><li><a href="https://github.com/huyingxi/Synonyms/">Synonyms:中文近义词工具包</a> 基于维基百科中文和word2vec训练的近义词库，封装为python包文件</li><li><a href="https://github.com/guotong1988/chinese_dictionary">同义词库、反义词库、否定词库</a></li><li><a href="https://github.com/wainshine/Chinese-Names-Corpus">中文人名语料库</a> 中文姓名,姓氏,名字,称呼,日本人名,翻译人名,英文人名。</li><li><a href="https://github.com/wainshine/Company-Names-Corpus">公司名、机构名语料库</a> 公司简称,缩写,品牌词,企业名。</li><li><a href="https://github.com/observerss/textfilter">中文敏感词词库 textfilter</a> 敏感词过滤的几种实现+某1w词敏感词库</li><li><a href="https://github.com/zhangyics/Chinese-abbreviation-dataset">中文简称/缩写词库</a> A corpus of Chinese abbreviation, including negative full forms.</li><li><a href="https://github.com/rainarch/SentiBridge/blob/master/Entity_Emotion_Express/CCF_data/pair_mine_result">词汇情感值</a>：如山泉水:0.400704566541、充沛: 0.37006739587</li><li><a href="http://thuctc.thunlp.org/">THU整理的词库</a>：IT词库、财经词库、成语词库、地名词库、历史名人词库、诗词词库、医学词库、饮食词库、法律词库、汽车词库、动物词库</li><li>中文字符数据：<a href="https://github.com/skishore/makemeahanzi">github</a></li><li><a href="https://github.com/liuhuanyong/DomainWordsDict">领域词典库 DomainWordsDict</a>：涵盖68个领域、共计916万词的专业词典知识库</li></ul><h2 id="超大型通用语料"><a href="#超大型通用语料" class="headerlink" title="超大型通用语料"></a>超大型通用语料</h2><div class="table-container"><table><thead><tr><th>语料名称</th><th>语料大小</th><th>语料描述</th></tr></thead><tbody><tr><td><a href="https://storage.googleapis.com/nlp_chinese_corpus/wiki_zh_2019.zip">维基百科json版(wiki2019zh)</a></td><td>104万个词条, 1.6G</td><td>做预训练的语料或构建词向量，也可以用于构建知识问答</td></tr><tr><td><a href="https://pan.baidu.com/s/1LJeq1dkA0wmYd9ZGZw72Xg">新闻语料json版(news2016zh)</a></td><td>250万篇新闻,原始数据9G</td><td>密码: film 包含了250万篇新闻。数据集划分：数据去重并分成三个部分。训练集：243万；验证集：7.7万；测试集，数万</td></tr><tr><td><a href="https://pan.baidu.com/s/12TCEwC_Q3He65HtPKN17cA">百科类问答json版(baike2018qa)</a></td><td>150万个问答,原始数据1G多</td><td>含有150万个预先过滤过的、高质量问题和答案，每个问题属于一个类别。总共有492个类别</td></tr><tr><td><a href="https://storage.googleapis.com/nlp_chinese_corpus/webtext2019zh.zip">社区问答json版(webtext2019zh)</a></td><td>410万个问答,过滤后数据3.7G</td><td>含有410万个预先过滤过的、高质量问题和回复。</td></tr></tbody></table></div><h2 id="领域特定语料"><a href="#领域特定语料" class="headerlink" title="领域特定语料"></a>领域特定语料</h2><div class="table-container"><table><thead><tr><th>语料名称</th><th>语料大小</th><th>语料描述</th></tr></thead><tbody><tr><td><a href="https://github.com/Samurais/insuranceqa-corpus-zh">保险行业QA语料库</a></td><td>未知</td><td>train_data含有问题12,889条，数据 141779条，正例：负例 = 1:10； test_data含有问题2,000条，数据 22000条，正例：负例 = 1:10；valid_data含有问题2,000条，数据 22000条，正例：负例 = 1:10</td></tr><tr><td><a href="https://github.com/smoothnlp/FinancialDatasets">FinancialDatasets</a></td><td>-</td><td>SmoothNLP 金融文本数据集(公开) Public Financial Datasets for NLP Researches Only</td></tr><tr><td><a href="https://cail.oss-cn-qingdao.aliyuncs.com/CAIL2018_ALL_DATA.zip">CAIL2018</a></td><td>-</td><td>2018中国‘法研杯’法律智能挑战赛（任务：罪名预测、法条推荐、刑期预测）的数据，数据集共包括268万刑法法律文书，共涉及183条罪名，202条法条，刑期长短包括0-25年、无期、死刑。</td></tr><tr><td><a href="https://github.com/Toyhom/Chinese-medical-dialogue-data">github</a></td><td>-</td><td>Chinese medical dialogue data 中文医疗对话数据集</td></tr><tr><td><a href="https://github.com/UCSD-AI4H/Medical-Dialogue-System">github</a></td><td>包含110万医学咨询，400万条医患对话</td><td>一个大规模医疗对话数据集</td></tr><tr><td><a href="https://github.com/abachaa/MedQuAD">github</a></td><td>-</td><td>MedQuAD(英文)医学问答数据集</td></tr></tbody></table></div><h2 id="NER-amp-POS-amp-分词"><a href="#NER-amp-POS-amp-分词" class="headerlink" title="NER &amp; POS &amp; 分词"></a>NER &amp; POS &amp; 分词</h2><div class="table-container"><table><thead><tr><th>语料名称</th><th>语料大小</th><th>语料描述</th></tr></thead><tbody><tr><td><a href="https://github.com/InsaneLife/ChineseNLPCorpus/tree/master/NER/MSRA">MSRA</a></td><td>5w+条</td><td>中文NER任务最常用数据之一，包含地名、人名和机构名三类</td></tr><tr><td><a href="https://github.com/OYE93/Chinese-NLP-Corpus/tree/master/NER/People&#39;s Daily">1998人民日报</a></td><td>137万多条</td><td>中文NER任务最常用数据之二，包含地名、人名和机构名三类实体类型。人民日报语料处理工具集 <a href="https://github.com/howl-anderson/tools_for_corpus_of_people_daily">github</a></td></tr><tr><td><a href="https://github.com/hltcoe/golden-horse">weibo NER corpus</a></td><td>1,890条</td><td>中文NER任务最常用数据之三。设计的实体有：人名、地点、组织、地理政治相关实体</td></tr><tr><td><a href="https://github.com/InsaneLife/ChineseNLPCorpus/tree/master/NER/boson">boson数据(不维护了)</a></td><td>2000条</td><td>包含6种实体类型：人名、地名、时间、组织名、公司名、产品名</td></tr><tr><td><a href="https://github.com/jiesutd/LatticeLSTM/tree/master/ResumeNER">Resume NER data</a></td><td>-</td><td>爬虫新浪财经的的简历数据, CoNLL format (BIOES tag scheme)，包括城市、学校、地点、人名、组织等</td></tr><tr><td><a href="https://github.com/LG-1/video_music_book_datasets">影视、音乐、书籍</a></td><td>大约10000条</td><td>包含 3 种实体：视频/音乐/书籍</td></tr><tr><td><a href="https://pan.baidu.com/s/17djsvYfpYUXrazL0H_mtoA">1300W字的新闻</a></td><td>未知</td><td>该语料可用于分词、NER、POS等任务。标记和格式请参考<a href="https://cloud.tencent.com/developer/article/1091906">此文章</a></td></tr><tr><td><a href="https://biendata.com/competition/CCKS2017_2/data/">CCKS2017中文电子病例命名实体识别</a></td><td>-</td><td>数据来源于其云医院平台的真实电子病历数据，共计800条（单个病人单次就诊记录），经脱敏处理</td></tr><tr><td><a href="https://biendata.com/competition/CCKS2018_1/data/">CCKS2018中文电子病例命名实体识别</a></td><td>-</td><td>CCKS2018的电子病历命名实体识别的评测任务提供了600份标注好的电子病历文本，共需识别含解剖部位、独立症状、症状描述、手术和药物五类实体</td></tr><tr><td><a href="https://storage.googleapis.com/cluebenchmark/tasks/cluener_public.zip">CLUE Fine-Grain NER</a></td><td>-</td><td>CLUENER2020数据集，是在清华大学开源的文本分类数据集THUCTC基础上，选出部分数据进行细粒度命名实体标注，原数据来源于Sina News RSS。数据包含10个标签类别，训练集共有10748条语料，验证集共有1343条语料</td></tr><tr><td><a href="https://github.com/lancopku/Chinese-Literature-NER-RE-Dataset">Chinese-Literature-NER-RE-Dataset</a></td><td>-</td><td>A Discourse-Level Named Entity Recognition and Relation Extraction Dataset for Chinese Literature Text</td></tr></tbody></table></div><h2 id="文本分类"><a href="#文本分类" class="headerlink" title="文本分类"></a>文本分类</h2><div class="table-container"><table><thead><tr><th>语料名称</th><th>语料大小</th><th>语料描述</th></tr></thead><tbody><tr><td><a href="https://cail.oss-cn-qingdao.aliyuncs.com/CAIL2018_ALL_DATA.zip">2018中国‘法研杯’法律智能挑战赛数据</a></td><td>未知</td><td>268万刑法法律文书，共涉及183条罪名，202条法条，刑期长短包括0-25年、无期、死刑</td></tr><tr><td><a href="https://github.com/fateleak/toutiao-text-classfication-dataset">今日头条中文新闻（短文本）</a></td><td>共38万条</td><td>15个分类中，包含民生、文化、娱乐、体育、财经、房产、骑车、教育、科技、军事、旅游、国际、证券、农业、电竞</td></tr><tr><td><a href="https://pan.baidu.com/s/1bnhXX6Z">搜狗20061127新闻语料(包含分类)@百度盘</a></td><td></td><td></td></tr><tr><td><a href="http://thuctc.thunlp.org/#%E8%8E%B7%E5%8F%96%E9%93%BE%E6%8E%A5">清华新闻分类语料</a></td><td>74万篇新闻文档（2.19 GB）</td><td>根据新浪新闻RSS订阅频道2005~2011年间的历史数据筛选过滤生成</td></tr><tr><td><a href="http://www.nlpir.org/?action-viewnews-itemid-145">中科大新闻分类语料库</a></td><td></td></tr></tbody></table></div><h2 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h2><div class="table-container"><table><thead><tr><th>数据集</th><th>数据概览</th><th>下载地址</th></tr></thead><tbody><tr><td>ez_douban</td><td>5 万多部电影（3 万多有电影名称，2 万多没有电影名称），2.8 万 用户，280 万条评分数据</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/ez_douban/intro.ipynb">点击查看</a></td></tr><tr><td>dmsc_v2</td><td>28 部电影，超 70 万 用户，超 200 万条 评分/评论 数据</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/dmsc_v2/intro.ipynb">点击查看</a></td></tr><tr><td>yf_dianping</td><td>24 万家餐馆，54 万用户，440 万条评论/评分数据</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/yf_dianping/intro.ipynb">点击查看</a></td></tr><tr><td>yf_amazon</td><td>52 万件商品，1100 多个类目，142 万用户，720 万条评论/评分数据</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/yf_amazon/intro.ipynb">点击查看</a></td></tr></tbody></table></div><h2 id="阅读理解"><a href="#阅读理解" class="headerlink" title="阅读理解"></a>阅读理解</h2><p>阅读理解数据集按照方法主要有：抽取式、分类（观点提取）。按照篇章又分为单篇章、多篇章，比如有的问题答案可能需要从多个文章中提取，每个文章可能都只是一部分，那么多篇章提取就会面临怎么合并，合并的时候怎么去掉重复的，保留补充的。</p><div class="table-container"><table><thead><tr><th>名称</th><th>规模</th><th>说明</th><th>单位</th><th>下载</th><th>评测</th></tr></thead><tbody><tr><td>DuReader</td><td>30万问题 140万文档 66万答案</td><td>问答阅读理解数据集</td><td>百度</td><td><a href="https://ai.baidu.com/broad/introduction?dataset=dureader">链接</a></td><td><a href="http://mrc2018.cipsc.org.cn/">2018 NLP Challenge on MRC</a>、<a href="http://lic2019.ccf.org.cn/">2019 Language and Intelligence Challenge on MRC</a></td></tr><tr><td>DuReaderrobust</td><td>2.2万问题</td><td>单篇章、抽取式阅读理解数据集</td><td>百度</td><td><a href="https://github.com/PaddlePaddle/Research/tree/master/NLP/DuReader-Robust-BASELINE">链接</a></td><td><a href="https://aistudio.baidu.com/aistudio/competition/detail/49/?isFromLUGE=TRUE">评测</a></td></tr><tr><td>CMRC 2018</td><td>2万问题</td><td>篇章片段抽取型阅读理解</td><td>哈工大讯飞联合实验室</td><td><a href="https://github.com/ymcui/cmrc2018">链接</a></td><td><a href="https://hfl-rc.github.io/cmrc2018/">第二届“讯飞杯”中文机器阅读理解评测</a></td></tr><tr><td>DuReaderyesno</td><td>9万</td><td>观点型阅读理解数据集</td><td>百度</td><td><a href="https://aistudio.baidu.com/aistudio/competition/detail/49/?isFromLUGE=TRUE">链接</a></td><td><a href="https://aistudio.baidu.com/aistudio/competition/detail/49/?isFromLUGE=TRUE">评测</a></td></tr><tr><td>DuReaderchecklist</td><td>1万</td><td>抽取式数据集</td><td>百度</td><td><a href="https://aistudio.baidu.com/aistudio/competition/detail/49/?isFromLUGE=TRUE">链接</a></td><td>-</td></tr></tbody></table></div><h2 id="FAQ-问答"><a href="#FAQ-问答" class="headerlink" title="FAQ 问答"></a>FAQ 问答</h2><div class="table-container"><table><thead><tr><th>数据集</th><th>数据概览</th><th>下载地址</th></tr></thead><tbody><tr><td>保险知道</td><td>8000 多条保险行业问答数据，包括用户提问、网友回答、最佳回答</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/baoxianzhidao/intro.ipynb">点击查看</a></td></tr><tr><td>安徽电信知道</td><td>15.6 万条电信问答数据，包括用户提问、网友回答、最佳回答</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/anhuidianxinzhidao/intro.ipynb">点击查看</a></td></tr><tr><td>金融知道</td><td>77 万条金融行业问答数据，包括用户提问、网友回答、最佳回答</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/financezhidao/intro.ipynb">点击查看</a></td></tr><tr><td>法律知道</td><td>3.6 万条法律问答数据，包括用户提问、网友回答、最佳回答</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/lawzhidao/intro.ipynb">点击查看</a></td></tr><tr><td>联通知道</td><td>20.3 万条联通问答数据，包括用户提问、网友回答、最佳回答</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/liantongzhidao/intro.ipynb">点击查看</a></td></tr><tr><td>农行知道</td><td>4 万条农业银行问答数据，包括用户提问、网友回答、最佳回答</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/nonghangzhidao/intro.ipynb">点击查看</a></td></tr><tr><td>保险知道</td><td>58.8 万条保险行业问答数据，包括用户提问、网友回答、最佳回答</td><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master/datasets/baoxianzhidao/intro.ipynb">点击查看</a></td></tr><tr><td>百度知道问答</td><td>包括超过580万的问题，每个问题带有问题标签。问答对983万个，每个问题的答案个数1.7个，问题标签个数5824个。</td><td><a href="https://github.com/liuhuanyong/MiningZhiDaoQACorpus">点击查看</a></td></tr><tr><td>DuReader</td><td>百度开源的一个QA和MRC数据集，共140万篇文档，30万个问题，及66万个答案。</td><td><a href="http://ai.baidu.com/broad/introduction?dataset=dureader">点击查看</a></td></tr><tr><td>社区问答数据</td><td>含有410万个预先过滤过的、高质量问题和回复。每个问题属于一个话题，总共有2.8万个各式话题，话题包罗万象。从1400万个原始问答中，筛选出至少获得3个点赞以上的的答案，代表了回复的内容比较不错或有趣，从而获得高质量的数据集。除了对每个问题对应一个话题、问题的描述、一个或多个回复外，每个回复还带有点赞数、回复ID、回复者的标签</td><td><a href="https://github.com/brightmart/nlp_chinese_corpus">点击查看</a></td></tr></tbody></table></div><h2 id="任务型对话数据"><a href="#任务型对话数据" class="headerlink" title="任务型对话数据"></a>任务型对话数据</h2><div class="table-container"><table><thead><tr><th>数据集</th><th>数据概览</th><th>下载地址</th></tr></thead><tbody><tr><td>任务型对话英文数据集</td><td>【最全任务型对话数据集】主要介绍了一份任务型对话数据集大全，这份数据集大全涵盖了到目前在任务型对话领域的所有常用数据集的主要信息。此外，为了帮助研究者更好的把握领域进展的脉络，我们以Leaderboard的形式给出了几个数据集上的State-of-the-art实验结果。</td><td><a href="https://github.com/AtmaHou/Task-Oriented-Dialogue-Dataset-Survey">github</a></td></tr><tr><td>Medical DS</td><td>复旦大学发布的基于百度拇指医生上真实对话数据的，面向任务型对话的中文医疗诊断数据集。</td><td><a href="http://www.sdspeople.fudan.edu.cn/zywei/data/acl2018-mds.zip">链接</a></td></tr><tr><td>千言数据集</td><td>包含知识对话、推荐对话、画像对话。千言里面还有很多数据集，见: <a href="https://www.luge.ai/#/">https://www.luge.ai/#/</a></td><td><a href="https://aistudio.baidu.com/aistudio/competition/detail/48/?isFromLUGE=TRUE">官网</a></td></tr><tr><td>JD客服对话数据</td><td>42GB的JD客服对话数据(CSDD)</td><td><a href="https://github.com/jd-aig/nlp_baai/tree/master/pretrained_models_and_embeddings">github</a></td></tr><tr><td><a href="https://sites.google.com/view/catslu/handbook">CATSLU</a></td><td>之前的一些对话数据集集中于语义理解，而工业界真实情况ASR也会有错误，往往被忽略。CATSLU而是一个中文语音+NLU文本理解的对话数据集，可以从语音信号到理解端到端进行实验，例如直接从音素建模语言理解（而非word or token）。</td><td><a href="https://sites.google.com/view/CATSLU/home">链接</a></td></tr><tr><td>NLPCC2018 Shared Task 4</td><td>中文真实商用车载语音任务型对话系统的对话日志.</td><td><a href="http://tcci.ccf.org.cn/conference/2018/dldoc/trainingdata04.zip">训练开发集</a> <a href="http://tcci.ccf.org.cn/conference/2018/dldoc/tasktestdata04.zip">测试集</a></td></tr><tr><td>SMP-2020-ECDT小样本对话语言理解数据集</td><td>来自于讯飞AIUI开放平台上真实用户语料和专家构造的语料(比例大概为3：7)</td><td><a href="https://atmahou.github.io/attachments/FewJoint.zip">链接</a></td></tr><tr><td><a href="https://github.com/HITlilingzhi/SMP2017ECDT-DATA">SMP2017中文人机对话评测数据</a></td><td>包含了两个任务的数据集，用户意图领域分类和特定域任务型人机对话在线评测。第一个数据集用得比较多。用户意图领域分类包含闲聊类、任务垂直类共三十一个类别，属于短文本分类的一个范畴</td><td><a href="https://github.com/HITlilingzhi/SMP2017ECDT-DATA">链接</a></td></tr><tr><td>SMP-2019-NLU</td><td>包含领域分类、意图识别和语义槽填充三项子任务的数据集</td><td><a href="https://github.com/InsaneLife/ChineseNLPCorpus/blob/master/dialogue/SMP-2019-NLU/train.json">trian.json</a></td></tr></tbody></table></div><h2 id="闲聊"><a href="#闲聊" class="headerlink" title="闲聊"></a>闲聊</h2><div class="table-container"><table><thead><tr><th>语料名称</th><th>语料Size</th><th>语料来源</th><th>语料描述</th></tr></thead><tbody><tr><td><a href="https://github.com/fate233/dgk_lost_conv">中文对白语料 chinese conversation corpus</a></td><td></td><td></td><td>可以用作聊天机器人的训练语料</td></tr><tr><td><a href="https://github.com/gunthercox/chatterbot-corpus/tree/master/chatterbot_corpus/data/chinese">chatterbot</a></td><td>560</td><td>开源项目</td><td>按类型分类，质量较高</td></tr><tr><td>qingyun（青云语料）</td><td>10W</td><td>某聊天机器人交流群</td><td>相对不错，生活化</td></tr><tr><td><a href="https://github.com/candlewill/Dialog_Corpus">xiaohuangji（小黄鸡语料）</a></td><td>45W</td><td>原人人网项目语料</td><td>有一些不雅对话，少量噪音</td></tr><tr><td><a href="https://github.com/MarkWuNLP/MultiTurnResponseSelection">douban（豆瓣多轮）</a></td><td>352W</td><td>来自北航和微软的paper, 开源项目</td><td>噪音相对较少，原本是多轮（平均7.6轮）</td></tr><tr><td><a href="https://github.com/ningshixian/NLP-zoo/blob/master">weibo（微博语料）</a></td><td>443W</td><td>来自华为的paper</td><td>有一些噪音</td></tr><tr><td><a href="https://github.com/thu-coai/CDial-GPT">中文闲聊语料库LCCC</a></td><td>??W</td><td>清华大学2020</td><td>大规模的中文闲聊语料库LCCC，从开源的文件上来看，这可能是目前开源的数量最大、质量最好的闲聊语料库了</td></tr><tr><td><a href="https://github.com/rustch3n/dgk_lost_conv">dgk_lost_conv 中文对白语料</a></td><td></td><td></td><td>chinese conversation corpus</td></tr><tr><td><a href="https://github.com/candlewill/Dialog_Corpus">用于训练中英文对话系统的语料库</a></td><td></td><td></td><td>Datasets for Training Chatbot System</td></tr><tr><td><a href="https://github.com/zake7749/Gossiping-Chinese-Corpus">八卦版問答中文語料</a></td><td></td><td></td><td></td></tr><tr><td><a href="https://github.com/codemayq/chaotbot_corpus_Chinese">中文公开聊天语料库</a></td><td></td><td></td></tr></tbody></table></div><h2 id="语义相似度"><a href="#语义相似度" class="headerlink" title="语义相似度"></a>语义相似度</h2><h3 id="哈工大-LCQMC-数据集"><a href="#哈工大-LCQMC-数据集" class="headerlink" title="哈工大 LCQMC 数据集"></a>哈工大 LCQMC 数据集</h3><p>LCQMC 是哈尔滨工业大学在自然语言处理国际顶会 COLING2018 构建的问题语义匹配数据集，其目标是判断两个问题的语义是否相同。该数据集的数据预览如下：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs">喜欢打篮球的男生喜欢什么样的女生爱打篮球的男生喜欢什么样的女生1 <br>我手机丢了，我想换个手机    我想买个新手机，求推荐1 <br>大家觉得她好看吗大家觉得跑男好看吗？0 <br></code></pre></td></tr></table></figure><br>原始数据集链接：<a href="http://icrc.hitsz.edu.cn/Article/show/171.html">http://icrc.hitsz.edu.cn/Article/show/171.html</a></p><h3 id="AFQMC-蚂蚁金融语义相似度数据集"><a href="#AFQMC-蚂蚁金融语义相似度数据集" class="headerlink" title="AFQMC 蚂蚁金融语义相似度数据集"></a>AFQMC 蚂蚁金融语义相似度数据集</h3><p>AFQMC（Ant Financial Question Matching Corpus）蚂蚁金融语义相似度数据集，用于问题相似度计算。即：给定客服里用户描述的两句话，用算法来判断是否表示了相同的语义。每一条数据有三个属性，分别是句子1，句子2，句子相似度标签。标签 “1” ：表示两个句子的语义类似；”0”：表示两个句子的语义不同。<br>原始数据为 json 格式，本仓库将其处理成形如 LCQMC 三列的格式，每列之间使用 ‘\t’ 分隔：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs">花呗消费超过额度有什么影响吗花呗额度成负数有啥影响吗1 <br>还款还清了，为什么花呗账单显示还要还款花呗全额还清怎么显示没有还款1 <br>花呗一次性付款有限制吗解除花呗支付限制0 <br></code></pre></td></tr></table></figure><br>原始数据集链接：<a href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=106411">https://tianchi.aliyun.com/dataset/dataDetail?dataId=106411</a></p><h3 id="OPPO-小布对话文本语义匹配数据集"><a href="#OPPO-小布对话文本语义匹配数据集" class="headerlink" title="OPPO 小布对话文本语义匹配数据集"></a>OPPO 小布对话文本语义匹配数据集</h3><p>该数据集通过对闲聊、智能客服、影音娱乐、信息查询等多领域真实用户交互语料进行用户信息脱敏、相似度筛选处理得到，数据主要特点是文本较短、非常口语化、存在文本高度相似而语义不同的难例。该数据集所有标签都有经过人工精标确认。<br>原始数据为 json 格式，本仓库将其处理成形如 LCQMC 三列的格式，每列之间使用 ‘\t’ 分隔：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs">我真的超级生气气死我了1 <br>你生日是几月几日你的老师生日是几月几日0 <br>打电话给爱老公给爱老公打电话1 <br></code></pre></td></tr></table></figure><br>原始数据集链接：<a href="https://tianchi.aliyun.com/competition/entrance/531851/introduction">https://tianchi.aliyun.com/competition/entrance/531851/introduction</a></p><h3 id="谷歌-PAWS-X-数据集"><a href="#谷歌-PAWS-X-数据集" class="headerlink" title="谷歌 PAWS-X 数据集"></a>谷歌 PAWS-X 数据集</h3><p>谷歌发布的同义句识别数据集，中文部分包含了释义对和非释义对，即识别一对句子是否具有相同的释义（含义），特点是具有高度重叠词汇，重点考察模型对句法结构的理解能力。该数据集的数据预览如下：<br><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">2</span><span class="hljs-number">1975</span>年的NBA赛季 -  <span class="hljs-number">76</span>赛季是全美篮球协会的第<span class="hljs-number">30</span>个赛季。<span class="hljs-number">1975</span>-<span class="hljs-number">76</span>赛季的全国篮球协会是NBA的第<span class="hljs-number">30</span>个赛季。<span class="hljs-number">1</span> <br><span class="hljs-attribute">3</span>还有具体的讨论，公众形象辩论和项目讨论。    还有公开讨论，特定档案讨论和项目讨论。<span class="hljs-number">0</span> <br><span class="hljs-attribute">4</span>当可以保持相当的流速时，结果很高。当可以保持可比较的流速时，结果很高。<span class="hljs-number">1</span> <br></code></pre></td></tr></table></figure><br>每条数据包含4列，分别表示数据 id，sentence1，sentence2 和 label，每列之间使用 ‘\t’ 分隔。<br>原始数据集链接：<a href="https://github.com/google-research-datasets/paws">https://github.com/google-research-datasets/paws</a></p><h3 id="北大中文文本复述数据集-PKU-Paraphrase-Bank"><a href="#北大中文文本复述数据集-PKU-Paraphrase-Bank" class="headerlink" title="北大中文文本复述数据集 PKU-Paraphrase-Bank"></a>北大中文文本复述数据集 PKU-Paraphrase-Bank</h3><p>北大发布的中文文本复述语料库，每条数据包含两列，分别表示两个具有相同含义的句子，列与列之间使用 ‘\t’ 分隔。该数据集一共有 509832 组句子对，平均每句 23.05 个词。<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs">莫雷尔指指肩膀，向士兵们暗示那是一个军官，应当给他找个地方暖和暖和。莫雷尔指着他的肩，向士兵们示意，这是一个军官，应当让他暖和一下。 <br>他细心地把斧头套在大衣里面的环扣里。他把斧子细心地挂在大衣里面的绳套上。 <br>仁慈的上帝！难道那时我灵魂中还有一丝精力未曾使用？仁慈的主呵！那时难道有我心灵中的任何一种能力不曾发挥么？ <br></code></pre></td></tr></table></figure><br>原始数据集链接：<a href="https://github.com/pkucoli/PKU-Paraphrase-Bank/">https://github.com/pkucoli/PKU-Paraphrase-Bank/</a></p><h3 id="Chinese-STS-B-数据集"><a href="#Chinese-STS-B-数据集" class="headerlink" title="Chinese-STS-B 数据集"></a>Chinese-STS-B 数据集</h3><p>该数据集通过翻译加部分人工修正的方法，从英文原数据集生成，可以一定程度上缓解中文语义相似度计算数据集不够的问题。每条数据包含三列，分别表示 sentence1、sentence2 和相似等级，相似等级范围为 0~5，5 表示语义一致，0 表示语义不相关。<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs">一架飞机要起飞了。一架飞机正在起飞。5 <br>一个男人在切面包。一个人在切洋葱。2 <br>一个男人在划独木舟。一个人在弹竖琴。0 <br>一个男人开着他的车。一个男人在开车。4 <br>三个男孩在跳舞。孩子们在跳舞。3 <br>一个人一只手握着一只小动物。一个男人在炫耀一只小猴子。1 <br></code></pre></td></tr></table></figure><br>原始数据集链接：<a href="https://github.com/pluto-junzeng/CNSD">https://github.com/pluto-junzeng/CNSD</a></p><h2 id="中文指令数据集"><a href="#中文指令数据集" class="headerlink" title="中文指令数据集"></a>中文指令数据集</h2><blockquote><p>收集包含中文的指令数据集，用于微调语言模型。</p></blockquote><div class="table-container"><table><thead><tr><th>模型</th><th>大小</th><th>语言</th><th>下载</th><th>作者</th><th>项目地址</th><th>备注</th></tr></thead><tbody><tr><td>Zhihu-KOL</td><td>/</td><td>中文</td><td><a href="https://huggingface.co/datasets/wangrui6/Zhihu-KOL">dataset</a></td><td><a href="https://huggingface.co/wangrui6">Rui Wang</a></td><td><a href="https://github.com/wangrui6/Zhihu-KOL">Zhihu-KOL</a></td></tr><tr><td></td></tr><tr><td>InstructionWild</td><td>104k</td><td>中英文</td><td><a href="https://github.com/XueFuzhao/InstructionWild/tree/main/data">dataset</a></td><td><a href="https://github.com/XueFuzhao">Xue Fuzhao</a></td><td><a href="https://github.com/XueFuzhao/InstructionWild">InstructionWild</a></td></tr><tr><td></td></tr><tr><td>GuanacoDataset</td><td>/</td><td>中/多语言</td><td><a href="https://huggingface.co/datasets/JosephusCheung/GuanacoDataset">dataset</a></td><td><a href="https://github.com/Guanaco-Model">Guanaco</a></td><td><a href="https://guanaco-model.github.io/">guanaco-model</a></td></tr><tr><td></td></tr><tr><td>Traditional-Chinese-alpaca</td><td>52K</td><td>中文</td><td><a href="https://github.com/ntunlplab/traditional-chinese-alpaca/tree/main/data">dataset</a></td><td><a href="https://github.com/ntunlplab">NTU NLP Lab</a></td><td><a href="https://github.com/ntunlplab/traditional-chinese-alpaca">Traditional-Chinese Alpaca</a></td><td>gpt翻译</td></tr><tr><td>alpaca_chinese_dataset</td><td>/</td><td>中文</td><td><a href="https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models/blob/main">dataset</a></td><td><a href="https://github.com/hikariming">akou</a></td><td><a href="https://github.com/hikariming/alpaca_chinese_dataset">alpaca_chinese_dataset</a></td><td>人工校验</td></tr><tr><td>alpaca-chinese-dataset</td><td>/</td><td>中文</td><td><a href="https://github.com/carbonz0/alpaca-chinese-dataset">dataset</a></td><td><a href="https://github.com/carbonz0">carbonz</a></td><td><a href="https://github.com/carbonz0/alpaca-chinese-dataset">alpaca-chinese-dataset</a></td><td>机器翻译</td></tr><tr><td>generated_train_1M_CN</td><td>1M</td><td>中文</td><td><a href="https://huggingface.co/datasets/BelleGroup/generated_train_1M_CN">dataset</a></td><td><a href="https://github.com/LianjiaTech">Ke Technologies</a></td><td><a href="https://github.com/LianjiaTech/BELLE">BELLE</a></td></tr><tr><td></td></tr><tr><td>generated_train_0.5M_CN</td><td>0.5M</td><td>中文</td><td><a href="https://huggingface.co/datasets/BelleGroup/generated_train_0.5M_CN">dataset</a></td><td><a href="https://github.com/LianjiaTech">Ke Technologies</a></td><td><a href="https://github.com/LianjiaTech/BELLE">BELLE</a></td></tr><tr><td></td></tr><tr><td>HC3 人类-ChatGPT 问答对比语料集（中文）</td><td>/</td><td>中文</td><td><a href="https://www.modelscope.cn/datasets/simpleai/HC3-Chinese/summary">dataset</a></td><td><a href="https://github.com/Hello-SimpleAI">SimpleAI</a></td><td><a href="https://github.com/Hello-SimpleAI/chatgpt-comparison-detection">chatgpt-comparison-detection</a></td></tr><tr><td></td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>LLM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Corpus</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PPO算法</title>
    <link href="/2023/03/14/PPO%E7%AE%97%E6%B3%95/"/>
    <url>/2023/03/14/PPO%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h2><ul><li>根据 OpenAI 的<a href="https://blog.openai.com/openai-baselines-ppo/">官方博客</a>, PPO 已经成为他们在强化学习上的默认算法. <strong>如果一句话概括 PPO: OpenAI 提出的一种解决 Policy Gradient 不好确定 Learning rate (或者 Step size) 的问题. 因为如果 step size 过大, 学出来的 Policy 会一直乱动, 不会收敛, 但如果 Step Size 太小, 对于完成训练, 我们会等到绝望. PPO 利用 New Policy 和 Old Policy 的比例, 限制了 New Policy 的更新幅度, 让 Policy Gradient 对稍微大点的 Step size 不那么敏感.</strong></li><li>总的来说 PPO 是一套 Actor-Critic 结构, Actor 想<strong>最大化</strong> J_PPO, Critic 想<strong>最小化</strong> L_BL.</li></ul><h2 id="PG-Add-Constraint-→-PPO"><a href="#PG-Add-Constraint-→-PPO" class="headerlink" title="PG Add Constraint → PPO"></a>PG Add Constraint → PPO</h2><p>简单来说，PPO就是Policy Gradient的”off-policy”版本。为了满足<strong>Importance Sampling</strong>的使用条件，即防止$p_{\theta}$和$p_{\theta_{old}}$两个概率分布相差太多，PPO提供了两个解决方案：</p><ol><li>TRPO（Trust Region Policy Optimization）在目标函数外使用KL Penalty (惩罚项）来限制策略更新，希望在训练的过程中，new Policy 和 old Policy 的输出不要相差太大（因为输出的 action 是概率分布，也即计算两个概率分布之间的差别）。但是这种方法实现起来很复杂，需要更多的计算时间。</li></ol><p>$L^{PPO}(\theta)=E_{t}\left[r_t(\theta) * A_{t}\right]-\beta·KL[\pi_{\theta_{init}}|\pi_{\theta}]$</p><ol><li>PPO-Clip 在目标函数中使用 <strong>Clipped surrogate objective function </strong>来直接裁剪概率比率。所要做的事情本质上和TRPO是一样的，都是为了让两个分布（$θ$和$θ’$）之间的差距不致过大</li></ol><p>$L^{C L I P}(\theta)=\hat{\mathbb{E}}_{t}\left[\min \left(r_{t}(\theta) \hat{A}_{t}, \operatorname{clip}\left(r_{t}(\theta), 1-\epsilon, 1+\epsilon\right) \hat{A}_{t}\right)\right]$</p><p>其中，$\beta$是可以动态调整的，称之为自适应KL惩罚（adaptive KL penalty）；$r_t(\theta)$表示Ratio Function，指产生同样的 token，在 Policy Model 和 Alignment Model 下的概率比值（It’s the probability of taking action a_t at state s_t in the current policy divided by the previous one. ）</p><p>$r_t(\theta)=\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}$</p><p>正如我们所看到的，$r_t(\theta)$表示当前策略和旧策略之间的概率比率，<strong>是估计旧策略和当前策略之间差异的一种简单方法</strong>。</p><ul><li>如果$r_t(\theta)&gt;1$，则在状态$s_t$下，动作$a_t$在当前策略中比旧策略更有可能执行。</li><li>如果$0&lt;r_t(\theta)&lt;1$，则在当前策略下执行该动作的可能性比旧策略下低。</li></ul><img src="/2023/03/14/PPO%E7%AE%97%E6%B3%95/1677118748202.png" class="" title="image.png"><h3 id="PPO-Clip-算法直观理解"><a href="#PPO-Clip-算法直观理解" class="headerlink" title="PPO-Clip 算法直观理解"></a>PPO-Clip 算法直观理解</h3><p>$L^{C L I P}(\theta)=\hat{\mathbb{E}}_{t}\left[\min \left(r_{t}(\theta) \hat{A}_{t}, \operatorname{clip}\left(r_{t}(\theta), 1-\epsilon, 1+\epsilon\right) \hat{A}_{t}\right)\right]$<br>$r_t(\theta)=\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}$</p><p>整个目标函数在$min$这个大括号里有两部分，最终对比两部分哪部分更小，就取哪部分的值。<br>在括号的第二部分中，</p><ul><li>首先是裁剪函数$clip$：如果$p_{\theta}(a_t|s_t)$和$p_{\theta^k}(a_t|s_t)$之间的概率比落在范围$(1-ε)$和$(1+ε)$之外，$\frac{p_{\theta}(a_t|s_t)}{p_{\theta^k}(a_t|s_t)}$将被剪裁，使得其值最小不小于$(1-ε)$，最大不大于$(1+ε)$</li></ul><img src="/2023/03/14/PPO%E7%AE%97%E6%B3%95/1677049573025.jpeg" class="" title="image.png"><ul><li>然后是$clip$括号外乘以$A^{\theta’}(s_t,a_t)$：当$A&gt;0$，则说明这是好动作，那么希望增大这个action的几率$p_{\theta}(a_t|s_t)$，但是又不希望两者差异，即比值$\frac{p_{\theta}(a_t|s_t)}{p_{\theta^k}(a_t|s_t)}$太悬殊，所以增大到比值为$1+ε$就不要再增加了；当$A&lt;0$，则说明该动作不是好动作，那么希望这个action出现的几率$p_{\theta}(a_t|s_t)$越小越好，但$\frac{p_{\theta}(a_t|s_t)}{p_{\theta^k}(a_t|s_t)}$最小不能小过$(1-ε)$</li></ul><img src="/2023/03/14/PPO%E7%AE%97%E6%B3%95/1677049702486-4c83f34e-d965-4fd1-8337-135872b51c60.png" class="" title="image.png"><p>换言之，这个裁剪算法和KL散度约束所要做的事情本质上是一样的，都是为了让两个分布之间的差距不致过大，但裁剪算法相对好实现，别看看起来复杂，其实代码很好写，示例如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python">// ratios即为重要性权重<br>// 括号里的environment_log_probs代表用于与环境交互的策略<br>ratios = torch.exp(log_probs - environment_log_probs)<br> <br>// 分别用sur_1、sur_2来计算公式的两部分<br><br>// 第一部分是重要性权重乘以优势函数<br>sur_1 = ratios * advs<br> <br>// 第二部分是具体的裁剪过程<br>sur_2 = torch.clamp(ratios, <span class="hljs-number">1</span> - clip_eps, <span class="hljs-number">1</span> + clip_eps) * advs<br> <br>// 最终看谁更小则取谁<br>clip_loss = -torch.<span class="hljs-built_in">min</span>(sur_1,sur_2).mean()<br></code></pre></td></tr></table></figure><h2 id="简单-PPO-的代码解读"><a href="#简单-PPO-的代码解读" class="headerlink" title="简单 PPO 的代码解读"></a>简单 PPO 的代码解读</h2><blockquote><p><a href="https://mofanpy.com/tutorials/machine-learning/reinforcement-learning/DPPO">https://mofanpy.com/tutorials/machine-learning/reinforcement-learning/DPPO</a></p></blockquote><p>我们用 Tensorflow 搭建神经网络, tensorboard 中可以看清晰的看到我们是如果搭建的:</p><img src="/2023/03/14/PPO%E7%AE%97%E6%B3%95/1679394322067.png" class="" title="image.png"><p>图中的 pi 就是我们的 Actor 了. 每次要进行 PPO 更新 Actor 和 Critic 的时候, 我们有需要将 pi 的参数复制给 oldpi. 这就是 update_oldpi 这个 operation 在做的事. Critic 和 Actor 的内部结构, 我们不会打开细说了. 因为就是一堆的神经网络而已. 这里的 Actor 使用了 normal distribution 正态分布输出动作.</p><p>这个 PPO 我们可以用一个 Python 的 class 代替:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PPO</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># 建 Actor Critic 网络</span><br>        <span class="hljs-comment"># 搭计算图纸 graph</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, s, a, r</span>):<br>        <span class="hljs-comment"># 更新 PPO</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">choose_action</span>(<span class="hljs-params">self, s</span>):<br>        <span class="hljs-comment"># 选动作</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_v</span>(<span class="hljs-params">self, s</span>):<br>        <span class="hljs-comment"># 算 state value</span><br></code></pre></td></tr></table></figure><p>而这个 PPO 和 env 环境的互动可以简化成这样.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs python">ppo = PPO()<br><span class="hljs-keyword">for</span> ep <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(EP_MAX):<br>    s = env.reset()<br>    buffer_s, buffer_a, buffer_r = [], [], []<br>    <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(EP_LEN):<br>        env.render()<br>        a = ppo.choose_action(s)<br>        s_, r, done, _ = env.step(a)<br>        buffer_s.append(s)<br>        buffer_a.append(a)<br>        buffer_r.append((r+<span class="hljs-number">8</span>)/<span class="hljs-number">8</span>)    <span class="hljs-comment"># normalize reward, 发现有帮助</span><br>        s = s_<br><br>        <span class="hljs-comment"># 如果 buffer 收集一个 batch 了或者 episode 完了</span><br>        <span class="hljs-keyword">if</span> (t+<span class="hljs-number">1</span>) % BATCH == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> t == EP_LEN-<span class="hljs-number">1</span>:<br>            <span class="hljs-comment"># 计算 discounted reward</span><br>            v_s_ = ppo.get_v(s_)<br>            discounted_r = []<br>            <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> buffer_r[::-<span class="hljs-number">1</span>]:<br>                v_s_ = r + GAMMA * v_s_<br>                discounted_r.append(v_s_)<br>            discounted_r.reverse()<br><br>            bs, ba, br = batch(buffer_s, buffer_a, discounted_r)<br>            <span class="hljs-comment"># 清空 buffer</span><br>            buffer_s, buffer_a, buffer_r = [], [], []<br>            ppo.update(bs, ba, br)  <span class="hljs-comment"># 更新 PPO</span><br></code></pre></td></tr></table></figure><p>了解了这些更新步骤, 我们就来看看如何更新我们的 PPO. 我们更新 Critic 的时候是根据 刚刚计算的 discounted_r 和自己分析出来的 state value 这两者的差 (advantage). 然后最小化这个差值:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PPO</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.advantage = self.tfdc_r - self.v   <span class="hljs-comment"># discounted reward - Critic 出来的 state value</span><br>        self.closs = tf.reduce_mean(tf.square(self.advantage))<br>        self.ctrain_op = tf.train.AdamOptimizer(C_LR).minimize(self.closs)<br><br></code></pre></td></tr></table></figure><p>两种更新 Actor 的方式 KL penalty 和 clipped surrogate objective</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PPO</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.tfa = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, A_DIM], <span class="hljs-string">&#x27;action&#x27;</span>)<br>        self.tfadv = tf.placeholder(tf.float32, [<span class="hljs-literal">None</span>, <span class="hljs-number">1</span>], <span class="hljs-string">&#x27;advantage&#x27;</span>)<br>        <span class="hljs-keyword">with</span> tf.variable_scope(<span class="hljs-string">&#x27;loss&#x27;</span>):<br>            <span class="hljs-keyword">with</span> tf.variable_scope(<span class="hljs-string">&#x27;surrogate&#x27;</span>):<br>                ratio = pi.prob(self.tfa) / oldpi.prob(self.tfa)<br>                surr = ratio * self.tfadv   <span class="hljs-comment"># surrogate objective</span><br>            <span class="hljs-keyword">if</span> METHOD[<span class="hljs-string">&#x27;name&#x27;</span>] == <span class="hljs-string">&#x27;kl_pen&#x27;</span>:      <span class="hljs-comment"># 如果用 KL penatily</span><br>                self.tflam = tf.placeholder(tf.float32, <span class="hljs-literal">None</span>, <span class="hljs-string">&#x27;lambda&#x27;</span>)<br>                kl = kl_divergence(oldpi, pi)<br>                self.kl_mean = tf.reduce_mean(kl)<br>                self.aloss = -(tf.reduce_mean(surr - self.tflam * kl))<br>            <span class="hljs-keyword">else</span>:                               <span class="hljs-comment"># 如果用 clipping 的方式</span><br>                self.aloss = -tf.reduce_mean(tf.minimum(<br>                    surr,<br>                    tf.clip_by_value(ratio, <span class="hljs-number">1.</span>-METHOD[<span class="hljs-string">&#x27;epsilon&#x27;</span>], <span class="hljs-number">1.</span>+METHOD[<span class="hljs-string">&#x27;epsilon&#x27;</span>])*self.tfadv))<br><br>        <span class="hljs-keyword">with</span> tf.variable_scope(<span class="hljs-string">&#x27;atrain&#x27;</span>):<br>            self.atrain_op = tf.train.AdamOptimizer(A_LR).minimize(self.aloss)<br><br></code></pre></td></tr></table></figure><p>好了, 接下来就是最重要的更新 PPO 时间了, 同样, 如果觉得我这些代码省略的很严重, 请直接前往我的 <a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/12_Proximal_Policy_Optimization/simply_PPO.py">Github 看全套代码</a>. 注意的是, 这个 update 的步骤里, 我们用 for loop 更新了很多遍 Actor 和 Critic, 在 loop 之前, pi 和 old pi 是一样的, 每次 loop 的之后, pi 会变动, 而 old pi 不变, 这样这个 surrogate 就会开始变动了. 这就是 PPO 的精辟.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PPO</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, s, a, r</span>):<br>        <span class="hljs-comment"># 先要将 oldpi 里的参数更新 pi 中的</span><br>        self.sess.run(self.update_oldpi_op)<br><br>        <span class="hljs-comment"># 更新 Actor 时, kl penalty 和 clipping 方式是不同的</span><br>        <span class="hljs-keyword">if</span> METHOD[<span class="hljs-string">&#x27;name&#x27;</span>] == <span class="hljs-string">&#x27;kl_pen&#x27;</span>:  <span class="hljs-comment"># 如果用 KL penalty</span><br>            <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(A_UPDATE_STEPS):<br>                _, kl = self.sess.run(<br>                        [self.atrain_op, self.kl_mean],<br>                        &#123;self.tfs: s, self.tfa: a, self.tfadv: adv, self.tflam: METHOD[<span class="hljs-string">&#x27;lam&#x27;</span>]&#125;)<br>                <span class="hljs-comment"># 之后根据 kl 的值, 调整 METHOD[&#x27;lam&#x27;] 这个参数</span><br>        <span class="hljs-keyword">else</span>:   <span class="hljs-comment"># 如果用 clipping 的方法</span><br>            [self.sess.run(self.atrain_op, &#123;self.tfs: s, self.tfa: a, self.tfadv: adv&#125;) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(A_UPDATE_STEPS)]<br><br>        <span class="hljs-comment"># 更新 Critic 的时候, 他们是一样的</span><br>        [self.sess.run(self.ctrain_op, &#123;self.tfs: s, self.tfdc_r: r&#125;) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(C_UPDATE_STEPS)]<br><br></code></pre></td></tr></table></figure><p>最后我们看一张学习的效果图:</p><img src="/2023/03/14/PPO%E7%AE%97%E6%B3%95/1679394584080.png" class="" title="image.png"><p>好了这就是整个 PPO 的主要流程了, 其他的步骤都没那么重要了, 可以直接在我的 <a href="https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/12_Proximal_Policy_Optimization/simply_PPO.py">Github 看全套代码</a> 中轻松弄懂. </p><h2 id="PPO-Actor-Critic-Loss"><a href="#PPO-Actor-Critic-Loss" class="headerlink" title="PPO Actor-Critic Loss"></a>PPO Actor-Critic Loss</h2><p>PPO Actor-Critic 风格的最终 Clipped Surrogate Objective Loss 看起来像这样，它是 Clipped Surrogate Objective 函数、Value Loss Function 和 Entropy bonus 的组合：</p><img src="/2023/03/14/PPO%E7%AE%97%E6%B3%95/image.png" class="" title="image.png"><p>DeepMind 总结 OpenAI conference 上的 PPO 的伪代码</p><img src="/2023/03/14/PPO%E7%AE%97%E6%B3%95/image2.png" class="" title="image.png"><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.51cto.com/u_15721703/5575736">李宏毅老师的深度强化学习课程</a><br><a href="https://huggingface.co/deep-rl-course/unit8/introduction-sf?fw=pt">Unit 8. Introduction to PPO - Hugging Face</a><br><a href="https://huggingface.co/blog">图解人工反馈强化学习(RLHF) - Hugging Face</a></p>]]></content>
    
    
    <categories>
      
      <category>强化学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PPO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PPO要点摘录</title>
    <link href="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/"/>
    <url>/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<p>PPO（Proximal Policy Optimization）算法中，状态、动作、价值函数、奖励和策略模型的含义如下：</p><ol><li>状态（state）：状态是指环境当前的状态，如：对话历史与之前生成的序列。在强化学习中，智能体需要根据当前状态来做出决策。</li><li>动作（action）：动作是指智能体在当前状态下选择的行动，如：生成每一个token，从词表中采样即是一个动作。在强化学习中，智能体需要根据当前状态选择一个最优的动作。</li><li>价值函数（Value Function）：价值函数则是智能体对自己行为好坏的评估，它可以帮助智能体更好地指导自己的决策。价值函数可以根据当前状态或状态-动作对，预测智能体能够获得的期望回报。比如，在一个赛车游戏中，如果智能体在某个状态下选择了某个动作，那么价值函数可以预测出这个动作会获得多少奖励分数。通过不断地优化价值函数，智能体可以学习到在环境中做出最优的决策。</li><li>奖励（Reward）：奖励函数就像是老师对学生的评分一样，通过环境的反馈，对智能体的行为进行评价，给出一个分数用来衡量智能体做出的动作是否正确。比如，在一个赛车游戏中，如果智能体成功完成一次绕过障碍的动作，那么就可以获得一定的奖励分数。通过不断地累积奖励分数，智能体可以学习到在环境中做出最优的动作。</li><li>策略模型（Policy Model）：策略模型是指智能体根据当前状态选择动作的概率分布。在PPO算法中，策略模型通常使用神经网络来进行建模，输出每个动作的概率。</li></ol><p>综上所述，PPO算法需要使用神经网络来表示价值函数和策略模型，根据当前状态选择动作，并通过环境的反馈来获得奖励。通过不断优化策略和价值函数，PPO算法可以使智能体在环境中获得更高的奖励，从而实现智能体的学习和决策能力的提高。</p><blockquote><p>参考：<a href="https://spinningup.openai.com/en/latest/algorithms/vpg.html">https://spinningup.openai.com/en/latest/algorithms/vpg.html</a></p></blockquote><p>actor在进行训练之前，会先与环境进行交互，然后得到一组训练数据（由多条状态序列构成）。</p><img src="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/46d23d87a5c5abf0ca1c48a7d816d46e.svg" class=""><p>每回合Trajectory<img src="https://cdn.nlark.com/yuque/__latex/ec1cc44b87fcbbced12dabd7375d36d3.svg#from=url&amp;id=SwJ8M&amp;originHeight=18&amp;originWidth=16&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;title=" alt="">的奖励</p><img src="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/299758ac4817013ed2822cdfc136f77a.svg" class=""><p>最终目标就是要使<strong>期望奖励最大</strong>！</p><img src="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/56897ebb6501e4a47704b198d7bcf5b9.svg" class=""><p>根据链式法则公式$\nabla \log f(x) = \frac{1}{f(x)} \nabla f(x)$，计算式(2)的梯度</p><img src="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/1678462247057-e3c72c54-7cbc-4ab6-a0da-f50a57ffe335.png" class="" title="image.png"><blockquote><p> <img src="https://cdn.nlark.com/yuque/0/2023/svg/8420697/1678463145871-d64a91f7-2168-4694-8f90-ad3b099a879a.svg#clientId=u6f13600c-cac6-4&amp;from=paste&amp;id=u2bca4fe6&amp;originHeight=13&amp;originWidth=26&amp;originalType=url&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;status=done&amp;style=none&amp;taskId=u3fe21edd-a2d2-441f-9acc-87d0a71c77c&amp;title=" alt="">是当前策略的优势函数<br>$\pi_{\theta}$表示带有参数$θ$的策略，$J(\pi_{\theta})$表示该策略的 期望回报</p></blockquote><p>策略梯度算法的工作原理是通过策略性能的随机梯度上升来更新策略参数：</p><p>$\theta ← \theta+\alpha\nabla{R}$</p><p>策略梯度（Policy Gradient）方法伪代码</p><img src="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/1678463814708-26dacbd5-6edf-4056-bdec-5cb2cea3e278.png" class="" title="image.png"><hr><p>为了使得训练资料可以反复使用，使用两个actor</p><p>其中，一个固定参数，另一个可训练，通过<strong>Importance Sampling</strong>来联系两个分布：</p><img src="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/1678285382558-74f3aa01-8cff-4c62-9528-a4b64c099e7c.png" class="" title="image.png"><blockquote><p>代入式4，梯度计算为：</p><img src="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/1678285679173-c8804740-750d-4df1-8344-982403686226.png" class="" title="image.png"><p><img src="https://cdn.nlark.com/yuque/0/2023/png/8420697/1678285693021-0331d447-0af9-4991-8da0-54016205c657.png#averageHue=%23f2f5f4&amp;clientId=uef89bebf-095c-4&amp;from=paste&amp;height=55&amp;id=u1633ed96&amp;name=image.png&amp;originHeight=110&amp;originWidth=804&amp;originalType=binary&amp;ratio=2&amp;rotation=0&amp;showTitle=false&amp;size=61955&amp;status=done&amp;style=none&amp;taskId=u234f4b37-ec52-4e28-a067-40e220a7611&amp;title=&amp;width=402" alt="image.png"></p></blockquote><p>代入式2，新的目标函数为：</p><p>$L=E_{\tau\in p_{\theta}(\tau)} [A(\tau)]=E_{\left(s_{t}, a_{t}\right) \sim \pi_{\theta^{\prime}}}\left[r_{\theta}(t)A^{\theta^{\prime}}\left(s_{t}, a_{t}\right)\right]$</p><p>$r_{\theta}(t)=\frac{p_{\theta}\left(a_{t} \mid s_{t}\right)}{p_{\theta^{\prime}}\left(a_{t} \mid s_{t}\right)}$</p><p>Advantages are computed using Generalized Advantage Estimation (GAE): $A_t$叫做策略优势估计，是PPO算法的核心!</p><img src="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/1678443935731-6516a589-895f-43e6-bcb3-59c661d81ad8.png" class="" title="image.png"><p>PPO 进一步给目标函数添加约束项，防止$p_{\theta}$和$p_{\theta’}$两个概率分布相差太多！PPO 是一种 on-policy 算法，有两种主要变体：PPO-Penalty 和 PPO-Clip。</p><ul><li>PPO-Penalty：</li></ul><p>$L(s,a,θ_k,θ) = r_{\theta}(t)·A^{\pi_{\theta k}}(s,a)-\beta·KL(θ,θ_k)$</p><p>$r_{\theta}(t)=\frac{\pi_{\theta}\left(a \mid s\right)}{\pi_{\theta^{\prime}}\left(a \mid s\right)}$</p><ul><li>PPO-Clip：</li></ul><img src="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/1678464277268-b4d8e192-dcc1-4e7f-9544-add909d41690.png" class="" title="image.png"><p>PPO方法伪代码</p><img src="/2023/03/14/PPO%20%E8%A6%81%E7%82%B9%E6%91%98%E5%BD%95/1678464873211-15bbc7ba-8930-4e13-abaf-a106d6df8151.png" class="" title="image.png"><p>符号解释：</p><ul><li>$p_{\theta}$表示可训练策略模型</li><li>$p_{\theta’}$表示参数固定的策略模型</li><li>$\frac{p_{\theta}(·)}{p_{\theta{‘}}(·)}$表示 Importance Sampling 系数，指产生同样的 token，在 Policy Model 和 Alignment Model 下的概率比值</li><li>$A$ 或$R$表示奖励，其给出一种利用长期奖励$r_t$与短期奖励$V({s_t})$计算当前步的好坏，在第t步的$A_t$分数越高，则代表该位置生成的质量越高。<ul><li>Reward Model，是一个固定参数的模型，其输出值$r_t$</li><li>Value Function Model，是一个可训练的价值函数，其输出值$V({s_t})$代表生成的每一个token的质量，是一个短期的奖励</li></ul></li><li>$KL()$表示KL散度，用作一个惩罚项，约束着每一次梯度更新以后不要产生与原模型相距甚远的回复。保证了模型训练的稳定性。</li></ul>]]></content>
    
    
    <categories>
      
      <category>强化学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PPO</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
